diff --git a/vendor/knative.dev/eventing/pkg/scheduler/state/helpers.go b/vendor/knative.dev/eventing/pkg/scheduler/state/helpers.go
index 56ca82b8d..b37fc7997 100644
--- a/vendor/knative.dev/eventing/pkg/scheduler/state/helpers.go
+++ b/vendor/knative.dev/eventing/pkg/scheduler/state/helpers.go
@@ -20,10 +20,8 @@ import (
 	"math"
 	"strconv"
 	"strings"
-	"time"
 
 	"k8s.io/apimachinery/pkg/types"
-	"k8s.io/apimachinery/pkg/util/wait"
 	"knative.dev/eventing/pkg/scheduler"
 )
 
@@ -51,13 +49,8 @@ func GetVPod(key types.NamespacedName, vpods []scheduler.VPod) scheduler.VPod {
 
 func SatisfyZoneAvailability(feasiblePods []int32, states *State) bool {
 	zoneMap := make(map[string]struct{})
-	var zoneName string
-	var err error
 	for _, podID := range feasiblePods {
-		wait.PollImmediate(50*time.Millisecond, 5*time.Second, func() (bool, error) {
-			zoneName, _, err = states.GetPodInfo(PodNameFromOrdinal(states.StatefulSetName, podID))
-			return err == nil, nil
-		})
+		zoneName, _, _ := states.GetPodInfo(PodNameFromOrdinal(states.StatefulSetName, podID))
 		zoneMap[zoneName] = struct{}{}
 	}
 	return len(zoneMap) == int(states.NumZones)
@@ -65,13 +58,8 @@ func SatisfyZoneAvailability(feasiblePods []int32, states *State) bool {
 
 func SatisfyNodeAvailability(feasiblePods []int32, states *State) bool {
 	nodeMap := make(map[string]struct{})
-	var nodeName string
-	var err error
 	for _, podID := range feasiblePods {
-		wait.PollImmediate(50*time.Millisecond, 5*time.Second, func() (bool, error) {
-			_, nodeName, err = states.GetPodInfo(PodNameFromOrdinal(states.StatefulSetName, podID))
-			return err == nil, nil
-		})
+		_, nodeName, _ := states.GetPodInfo(PodNameFromOrdinal(states.StatefulSetName, podID))
 		nodeMap[nodeName] = struct{}{}
 	}
 	return len(nodeMap) == int(states.NumNodes)
diff --git a/vendor/knative.dev/eventing/pkg/scheduler/state/state.go b/vendor/knative.dev/eventing/pkg/scheduler/state/state.go
index fcc758cd3..bab000958 100644
--- a/vendor/knative.dev/eventing/pkg/scheduler/state/state.go
+++ b/vendor/knative.dev/eventing/pkg/scheduler/state/state.go
@@ -20,8 +20,8 @@ import (
 	"context"
 	"encoding/json"
 	"errors"
+	"fmt"
 	"strconv"
-	"time"
 
 	"go.uber.org/zap"
 	v1 "k8s.io/api/core/v1"
@@ -29,13 +29,14 @@ import (
 	"k8s.io/apimachinery/pkg/labels"
 	"k8s.io/apimachinery/pkg/types"
 	"k8s.io/apimachinery/pkg/util/sets"
-	"k8s.io/apimachinery/pkg/util/wait"
 	clientappsv1 "k8s.io/client-go/kubernetes/typed/apps/v1"
 	corev1 "k8s.io/client-go/listers/core/v1"
 
 	kubeclient "knative.dev/pkg/client/injection/kube/client"
 	"knative.dev/pkg/logging"
 
+	apierrors "k8s.io/apimachinery/pkg/api/errors"
+
 	"knative.dev/eventing/pkg/scheduler"
 )
 
@@ -227,11 +228,11 @@ func (s *stateBuilder) State(reserved map[types.NamespacedName]map[string]int32)
 	}
 
 	for podId := int32(0); podId < scale.Spec.Replicas && s.podLister != nil; podId++ {
-		var pod *v1.Pod
-		wait.PollImmediate(50*time.Millisecond, 5*time.Second, func() (bool, error) {
-			pod, err = s.podLister.Get(PodNameFromOrdinal(s.statefulSetName, podId))
-			return err == nil, nil
-		})
+		podName := PodNameFromOrdinal(s.statefulSetName, podId)
+		pod, err := s.podLister.Get(podName)
+		if err != nil && !apierrors.IsNotFound(err) {
+			return nil, fmt.Errorf("failed to get pod %s from lister: %w", podName, err)
+		}
 
 		if pod != nil {
 			if isPodUnschedulable(pod) {
@@ -275,11 +276,10 @@ func (s *stateBuilder) State(reserved map[types.NamespacedName]map[string]int32)
 
 			withPlacement[vpod.GetKey()][podName] = true
 
-			var pod *v1.Pod
-			wait.PollImmediate(50*time.Millisecond, 5*time.Second, func() (bool, error) {
-				pod, err = s.podLister.Get(podName)
-				return err == nil, nil
-			})
+			pod, err := s.podLister.Get(podName)
+			if err != nil && !apierrors.IsNotFound(err) {
+				return nil, fmt.Errorf("failed to get pod %s from lister: %w", podName, err)
+			}
 
 			if pod != nil && schedulablePods.Has(OrdinalFromPodName(pod.GetName())) {
 				nodeName := pod.Spec.NodeName       //node name for this pod
@@ -300,11 +300,10 @@ func (s *stateBuilder) State(reserved map[types.NamespacedName]map[string]int32)
 					continue
 				}
 
-				var pod *v1.Pod
-				wait.PollImmediate(50*time.Millisecond, 5*time.Second, func() (bool, error) {
-					pod, err = s.podLister.Get(podName)
-					return err == nil, nil
-				})
+				pod, err := s.podLister.Get(podName)
+				if err != nil && !apierrors.IsNotFound(err) {
+					return nil, fmt.Errorf("failed to get pod %s from pod lister: %w", podName, err)
+				}
 
 				if pod != nil && schedulablePods.Has(OrdinalFromPodName(pod.GetName())) {
 					nodeName := pod.Spec.NodeName       //node name for this pod
diff --git a/vendor/knative.dev/eventing/pkg/scheduler/statefulset/autoscaler.go b/vendor/knative.dev/eventing/pkg/scheduler/statefulset/autoscaler.go
index 203d3963f..66195f367 100644
--- a/vendor/knative.dev/eventing/pkg/scheduler/statefulset/autoscaler.go
+++ b/vendor/knative.dev/eventing/pkg/scheduler/statefulset/autoscaler.go
@@ -18,6 +18,7 @@ package statefulset
 
 import (
 	"context"
+	"fmt"
 	"math"
 	"sync"
 	"sync/atomic"
@@ -25,6 +26,7 @@ import (
 
 	"go.uber.org/zap"
 	v1 "k8s.io/api/core/v1"
+	apierrors "k8s.io/apimachinery/pkg/api/errors"
 	metav1 "k8s.io/apimachinery/pkg/apis/meta/v1"
 	"k8s.io/apimachinery/pkg/types"
 	"k8s.io/apimachinery/pkg/util/wait"
@@ -54,7 +56,13 @@ type Autoscaler interface {
 
 	// Autoscale is used to immediately trigger the autoscaler with the hint
 	// that pending number of vreplicas couldn't be scheduled.
-	Autoscale(ctx context.Context, attemptScaleDown bool, pending int32)
+	Autoscale(ctx context.Context, trigger AutoscaleTrigger)
+}
+
+type AutoscaleTrigger struct {
+	Reseved         Reseved
+	AttempScaleDown bool
+	Pending         int32
 }
 
 type autoscaler struct {
@@ -63,15 +71,16 @@ type autoscaler struct {
 	vpodLister        scheduler.VPodLister
 	logger            *zap.SugaredLogger
 	stateAccessor     st.StateAccessor
-	trigger           chan int32
+	trigger           chan AutoscaleTrigger
 	evictor           scheduler.Evictor
 
 	// capacity is the total number of virtual replicas available per pod.
 	capacity int32
 
 	// refreshPeriod is how often the autoscaler tries to scale down the statefulset
-	refreshPeriod time.Duration
-	lock          sync.Locker
+	refreshPeriod      time.Duration
+	lastCompactAttempt time.Time
+	lock               sync.Locker
 
 	// isLeader signals whether a given autoscaler instance is leader or not.
 	// The autoscaler is considered the leader when ephemeralLeaderElectionObject is in a
@@ -108,53 +117,64 @@ func newAutoscaler(ctx context.Context, cfg *Config, stateAccessor st.StateAcces
 		vpodLister:        cfg.VPodLister,
 		stateAccessor:     stateAccessor,
 		evictor:           cfg.Evictor,
-		trigger:           make(chan int32, 1),
+		trigger:           make(chan AutoscaleTrigger, 20),
 		capacity:          cfg.PodCapacity,
 		refreshPeriod:     cfg.RefreshPeriod,
+		// Anything that is less than now() - refreshPeriod, so that we will try to compact
+		// as soon as we start.
+		lastCompactAttempt: time.Now().
+			Add(-cfg.RefreshPeriod).
+			Add(-time.Minute),
 		lock:              new(sync.Mutex),
 		isLeader:          atomic.Bool{},
 	}
 }
 
 func (a *autoscaler) Start(ctx context.Context) {
-	attemptScaleDown := false
-	pending := int32(0)
+	a.maybeTriggerAutoscaleOnStart()
 	for {
 		select {
 		case <-ctx.Done():
 			return
-		case <-time.After(a.refreshPeriod):
-			attemptScaleDown = true
-		case pending = <-a.trigger:
-			attemptScaleDown = false
+		case t := <-a.trigger:
+			a.syncAutoscale(ctx, t)
 		}
+	}
+}
 
-		// Retry a few times, just so that we don't have to wait for the next beat when
-		// a transient error occurs
-		a.syncAutoscale(ctx, attemptScaleDown, pending)
-		pending = int32(0)
+// maybeTriggerAutoscaleOnStart triggers the autoscaler when it is started when the vpodLister
+// returns no vpods.
+func (a *autoscaler) maybeTriggerAutoscaleOnStart() {
+	_, err := a.vpodLister()
+	if err != nil {
+		a.logger.Warnw("failed to list vpods", "err", err)
+	} else {
+		a.trigger <- AutoscaleTrigger{AttempScaleDown: true, Pending: 0}
 	}
 }
 
-func (a *autoscaler) Autoscale(ctx context.Context, attemptScaleDown bool, pending int32) {
-	a.syncAutoscale(ctx, attemptScaleDown, pending)
+func (a *autoscaler) Autoscale(ctx context.Context, trigger AutoscaleTrigger) {
+	select {
+	case a.trigger <- trigger:
+	default:
+	}
 }
 
-func (a *autoscaler) syncAutoscale(ctx context.Context, attemptScaleDown bool, pending int32) {
+func (a *autoscaler) syncAutoscale(ctx context.Context, trigger AutoscaleTrigger) {
 	a.lock.Lock()
 	defer a.lock.Unlock()
 
 	wait.Poll(500*time.Millisecond, 5*time.Second, func() (bool, error) {
-		err := a.doautoscale(ctx, attemptScaleDown, pending)
+		err := a.doautoscale(ctx, trigger)
 		return err == nil, nil
 	})
 }
 
-func (a *autoscaler) doautoscale(ctx context.Context, attemptScaleDown bool, pending int32) error {
+func (a *autoscaler) doautoscale(ctx context.Context, trigger AutoscaleTrigger) error {
 	if !a.isLeader.Load() {
 		return nil
 	}
-	state, err := a.stateAccessor.State(nil)
+	state, err := a.stateAccessor.State(trigger.Reseved)
 	if err != nil {
 		a.logger.Info("error while refreshing scheduler state (will retry)", zap.Error(err))
 		return err
@@ -168,9 +188,9 @@ func (a *autoscaler) doautoscale(ctx context.Context, attemptScaleDown bool, pen
 	}
 
 	a.logger.Infow("checking adapter capacity",
-		zap.Int32("pending", pending),
+		zap.Int32("pending", trigger.Pending),
 		zap.Int32("replicas", scale.Spec.Replicas),
-		zap.Int32("last ordinal", state.LastOrdinal))
+		zap.Any("state", state))
 
 	var scaleUpFactor, newreplicas, minNumPods int32
 	scaleUpFactor = 1                                                                                         // Non-HA scaling
@@ -184,13 +204,13 @@ func (a *autoscaler) doautoscale(ctx context.Context, attemptScaleDown bool, pen
 	newreplicas = state.LastOrdinal + 1 // Ideal number
 
 	// Take into account pending replicas and pods that are already filled (for even pod spread)
-	if pending > 0 {
+	if trigger.Pending > 0 {
 		// Make sure to allocate enough pods for holding all pending replicas.
 		if state.SchedPolicy != nil && contains(state.SchedPolicy.Predicates, nil, st.EvenPodSpread) && len(state.FreeCap) > 0 { //HA scaling across pods
 			leastNonZeroCapacity := a.minNonZeroInt(state.FreeCap)
-			minNumPods = int32(math.Ceil(float64(pending) / float64(leastNonZeroCapacity)))
+			minNumPods = int32(math.Ceil(float64(trigger.Pending) / float64(leastNonZeroCapacity)))
 		} else {
-			minNumPods = int32(math.Ceil(float64(pending) / float64(a.capacity)))
+			minNumPods = int32(math.Ceil(float64(trigger.Pending) / float64(a.capacity)))
 		}
 		newreplicas += int32(math.Ceil(float64(minNumPods)/float64(scaleUpFactor)) * float64(scaleUpFactor))
 	}
@@ -201,10 +221,16 @@ func (a *autoscaler) doautoscale(ctx context.Context, attemptScaleDown bool, pen
 	}
 
 	// Only scale down if permitted
-	if !attemptScaleDown && newreplicas < scale.Spec.Replicas {
+	if !trigger.AttempScaleDown && newreplicas < scale.Spec.Replicas {
 		newreplicas = scale.Spec.Replicas
 	}
 
+	a.logger.Debugw("Final scaling decision",
+		zap.Int32("expected", newreplicas),
+		zap.Int32("got", scale.Spec.Replicas),
+		zap.Bool("attempScaleDown", trigger.AttempScaleDown),
+	)
+
 	if newreplicas != scale.Spec.Replicas {
 		scale.Spec.Replicas = newreplicas
 		a.logger.Infow("updating adapter replicas", zap.Int32("replicas", scale.Spec.Replicas))
@@ -214,7 +240,7 @@ func (a *autoscaler) doautoscale(ctx context.Context, attemptScaleDown bool, pen
 			a.logger.Errorw("updating scale subresource failed", zap.Error(err))
 			return err
 		}
-	} else if attemptScaleDown {
+	} else if trigger.AttempScaleDown {
 		// since the number of replicas hasn't changed and time has approached to scale down,
 		// take the opportunity to compact the vreplicas
 		a.mayCompact(state, scaleUpFactor)
@@ -223,6 +249,24 @@ func (a *autoscaler) doautoscale(ctx context.Context, attemptScaleDown bool, pen
 }
 
 func (a *autoscaler) mayCompact(s *st.State, scaleUpFactor int32) {
+	// This avoids a too aggressive scale down by adding a "grace period" based on the refresh
+	// period
+	nextAttempt := a.lastCompactAttempt.Add(a.refreshPeriod)
+	if time.Now().Before(nextAttempt) {
+		a.logger.Debugw("Compact was retried before refresh period",
+			zap.Time("lastCompactAttempt", a.lastCompactAttempt),
+			zap.Time("nextAttempt", nextAttempt),
+			zap.String("refreshPeriod", a.refreshPeriod.String()),
+		)
+		return
+	}
+
+	a.logger.Debugw("Trying to compact and scale down",
+		zap.Int32("scaleUpFactor", scaleUpFactor),
+		zap.Any("schedulablePods", s.SchedulablePods),
+		zap.Any("state", s),
+	)
+
 	// when there is only one pod there is nothing to move or number of pods is just enough!
 	if s.LastOrdinal < 1 || len(s.SchedulablePods) <= int(scaleUpFactor) {
 		return
@@ -235,6 +279,7 @@ func (a *autoscaler) mayCompact(s *st.State, scaleUpFactor int32) {
 		usedInLastPod := s.Capacity - s.Free(s.LastOrdinal)
 
 		if freeCapacity >= usedInLastPod {
+			a.lastCompactAttempt = time.Now()
 			err := a.compact(s, scaleUpFactor)
 			if err != nil {
 				a.logger.Errorw("vreplicas compaction failed", zap.Error(err))
@@ -276,16 +321,18 @@ func (a *autoscaler) compact(s *st.State, scaleUpFactor int32) error {
 				ordinal := st.OrdinalFromPodName(placements[i].PodName)
 
 				if ordinal == s.LastOrdinal-j {
-					wait.PollImmediate(50*time.Millisecond, 5*time.Second, func() (bool, error) {
-						if s.PodLister != nil {
-							pod, err = s.PodLister.Get(placements[i].PodName)
+					if s.PodLister != nil {
+						pod, err = s.PodLister.Get(placements[i].PodName)
+						if apierrors.IsNotFound(err) {
+							continue
+						}
+						if err != nil {
+							return fmt.Errorf("failed to get pod %s: %w", placements[i].PodName, err)
+						}
+						err = a.evictor(pod, vpod, &placements[i])
+						if err != nil {
+							return err
 						}
-						return err == nil, nil
-					})
-
-					err = a.evictor(pod, vpod, &placements[i])
-					if err != nil {
-						return err
 					}
 				}
 			}
diff --git a/vendor/knative.dev/eventing/pkg/scheduler/statefulset/scheduler.go b/vendor/knative.dev/eventing/pkg/scheduler/statefulset/scheduler.go
index a1b5985e6..e7149b792 100644
--- a/vendor/knative.dev/eventing/pkg/scheduler/statefulset/scheduler.go
+++ b/vendor/knative.dev/eventing/pkg/scheduler/statefulset/scheduler.go
@@ -146,6 +146,8 @@ type StatefulSetScheduler struct {
 	reserved map[types.NamespacedName]map[string]int32
 }
 
+type Reseved map[types.NamespacedName]map[string]int32
+
 var (
 	_ reconciler.LeaderAware = &StatefulSetScheduler{}
 	_ scheduler.Scheduler    = &StatefulSetScheduler{}
@@ -226,6 +228,13 @@ func (s *StatefulSetScheduler) Schedule(vpod scheduler.VPod) ([]duckv1alpha1.Pla
 }
 
 func (s *StatefulSetScheduler) scheduleVPod(vpod scheduler.VPod) ([]duckv1alpha1.Placement, error) {
+	// Attempt to scale down (async)
+	defer s.autoscaler.Autoscale(s.ctx, AutoscaleTrigger{
+		Reseved:         s.copyReserved(),
+		AttempScaleDown: true,
+		Pending:         s.pendingVReplicas(),
+	})
+
 	logger := s.logger.With("key", vpod.GetKey())
 	logger.Infow("scheduling", zap.Any("pending", toJSONable(s.pending)))
 
@@ -310,9 +319,13 @@ func (s *StatefulSetScheduler) scheduleVPod(vpod scheduler.VPod) ([]duckv1alpha1
 
 		s.pending[vpod.GetKey()] = left
 
-		// Trigger the autoscaler
+		// Trigger the autoscaler (async)
 		if s.autoscaler != nil {
-			s.autoscaler.Autoscale(s.ctx, false, s.pendingVReplicas())
+			s.autoscaler.Autoscale(s.ctx, AutoscaleTrigger{
+				Reseved:         s.copyReserved(),
+				AttempScaleDown: false,
+				Pending:         s.pendingVReplicas(),
+			})
 		}
 
 		if state.SchedPolicy != nil {
@@ -347,8 +360,10 @@ func (s *StatefulSetScheduler) rebalanceReplicasWithPolicy(vpod scheduler.VPod,
 }
 
 func (s *StatefulSetScheduler) removeReplicasWithPolicy(vpod scheduler.VPod, diff int32, placements []duckv1alpha1.Placement) []duckv1alpha1.Placement {
-	logger := s.logger.Named("remove replicas with policy")
+	logger := s.logger.With(zap.String("action", "remove replicas with policy"))
+
 	numVreps := diff
+	logger.Debug(zap.Int32("numVreps", numVreps))
 
 	for i := int32(0); i < numVreps; i++ { //deschedule one vreplica at a time
 		state, err := s.stateAccessor.State(s.reserved)
@@ -415,9 +430,11 @@ func (s *StatefulSetScheduler) removeSelectionFromPlacements(placementPodID int3
 }
 
 func (s *StatefulSetScheduler) addReplicasWithPolicy(vpod scheduler.VPod, diff int32, placements []duckv1alpha1.Placement) ([]duckv1alpha1.Placement, int32) {
-	logger := s.logger.Named("add replicas with policy")
+	logger := s.logger.With(zap.String("action", "add replicas with policy"))
 
 	numVreps := diff
+	logger.Debug(zap.Int32("numVreps", numVreps))
+
 	for i := int32(0); i < numVreps; i++ { //schedule one vreplica at a time (find most suitable pod placement satisying predicates with high score)
 		// Get the current placements state
 		state, err := s.stateAccessor.State(s.reserved)
@@ -433,6 +450,8 @@ func (s *StatefulSetScheduler) addReplicasWithPolicy(vpod scheduler.VPod, diff i
 			break               //end the iteration for all vreps since there are not pods
 		}
 
+		logger.Debug("Finding feasible pods")
+
 		feasiblePods := s.findFeasiblePods(s.ctx, state, vpod, state.SchedPolicy)
 		if len(feasiblePods) == 0 { //no pods available to schedule this vreplica
 			logger.Info("no feasible pods available to schedule this vreplica")
@@ -451,6 +470,8 @@ func (s *StatefulSetScheduler) addReplicasWithPolicy(vpod scheduler.VPod, diff i
 			continue
 		} */
 
+		logger.Debug("Prioritizing pods")
+
 		priorityList, err := s.prioritizePods(s.ctx, state, vpod, feasiblePods, state.SchedPolicy)
 		if err != nil {
 			logger.Info("error while scoring pods using priorities", zap.Error(err))
@@ -800,3 +821,15 @@ func (s *StatefulSetScheduler) notEnoughPodReplicas(left int32) error {
 		controller.NewRequeueAfter(5*time.Second),
 	)
 }
+
+func (s *StatefulSetScheduler) copyReserved() Reseved {
+	reserved := make(Reseved, len(s.reserved))
+	for k, v := range s.reserved {
+		vv := make(map[string]int32, len(v))
+		for k1, v1 := range v {
+			vv[k1] = v1
+		}
+		reserved[k] = vv
+	}
+	return reserved
+}
